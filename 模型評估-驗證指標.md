# 如何評估模型的成效呢?
有一些驗整指標能當成成效指標，依據應用分為[分類指標]和[回歸指標]。
* 「分類指標」:
  二元相關(二元混淆矩陣和相對應驗證指標、ROC曲線、AUC)
  和多元相關(多元混淆矩陣和相對應驗證指標)。
Note:二元指標內有比較多diagnosis index算法和介紹。

* 「回歸指標」:
  平均均方誤差(Mean Squared Error, MSE)、平均絕對誤差(Mean Absolute Error, MAE)
  和平均均方對數誤差(Mean Squared Logarithmic Error, MSLE)

## 分類指標(Classification metrics)
大概分成二元分類(binary case)和多元分類(multiclass case)，所有的分類問題都可以先產生出一個稱為混淆矩陣(Confusion matrix)的東西，然後從這個矩陣在去算出一些成效指標。

### 二元混淆矩陣(Confusion matrix)
Positive就是「有」、「真」或是「正」，在醫學上通常用「有發病」；
Negative就是「沒有」、「假」或是「負」，在醫學上通常用「沒有發病」。

True Positive (TP)「真陽性」:真實情況是「有」，模型說「有」的個數。
True Negative(TN)「真陰性」:真實情況是「沒有」，模型說「沒有」的個數。
False Positive (FP)「偽陽性」:真實情況是「沒有」，模型說「有」的個數。
False Negative(FN)「偽陰性」:真實情況是「有」，模型說「沒有」的個數。
![image](https://github.com/user-attachments/assets/af9781be-4eaa-4dd7-978a-7d334a9e49c1)

常用的指標:
Sensitivity 靈敏性: 也稱為True Positive Rate (TPR), Recall，「有病的偵測率」，所以是越高越好。
Specificity 特異性: 也稱為True negative rate (TNR)，「沒病的偵測率」，也是越高越好。
但基本上這兩個指標是trade off，這兩個指標跟等會要介紹的ROC有關係，也是臨床上非常長看的兩個指標。

Accuracy正確率: 基本上就是模型的整體判斷的正確率，所以有時候也稱為overall accuracy，越高越好。
False Negative Rate 偽陰性率: 預測模型判成沒病，但實際上有病的比率，越小越好。
False Positive Rate (FPR) 偽陽性率: 預測模型判成有病，但實際上沒有病的比率，越小越好。
Positive predictive value (PPV) 陽性預測值: 也稱為Precision，在臨床上也是很常用的指標，模型診斷結果呈現有病且確實有病者的比率，越高越好。
Negative predictive value (NPV) 陰性預測值: 模型診斷結果呈沒病且實際上也沒有病的比率，越高越好。

### ROC曲線 (Receiver operating characteristic curve) & AUC (Area Under Curve)
ROC曲線（Receiver Operating Characteristic Curve，接收者操作特徵曲線）是一種用來評估二元分類模型性能的方法。它通過繪製**真陽性率（True Positive Rate, TPR）對假陽性率（False Positive Rate, FPR）**的曲線來展示分類器的性能。在這個曲線上：

真陽性率 (TPR) 表示模型能夠正確識別出正類樣本的比例，計算公式為 
![image](https://github.com/user-attachments/assets/abb39ba0-efe1-4710-b7cd-eea7d4159829)
，其中 TP 是真陽性數量，FN 是假陰性數量。

假陽性率 (FPR) 表示模型錯誤地將負類樣本分類為正類的比例，計算公式為 
![image](https://github.com/user-attachments/assets/fde34c43-4fc2-4aa4-86e2-d131be662723)
其中 FP 是假陽性數量，TN 是真陰性數量。

![image](https://github.com/user-attachments/assets/ecb7db1e-a004-4f02-b309-0560fc082af1)
AUC（Area Under the Curve） 是ROC曲線下的面積，用來量化ROC曲線的優劣。AUC值在0.5到1之間，越接近1表示模型性能越好，意味著模型能夠更準確地區分正負類樣本。

### 多元分類(multiclass case)指標

如果有玩過UCI資料庫的/機器學習課程的人，應該都知道鳶尾花分類的問題，假設我的預測模型是SVM，所以我得到下面這個這麼好的結果，只有在Iris-versicolor這類別分錯了兩個樣本。
![image](https://github.com/user-attachments/assets/78ec518f-dd16-47d9-ab31-90abeb4ef6a3)

Cohen's kappa coefficient 是一種統計量，用於衡量兩名觀察者（或分類器）在分類任務中的一致性。它可以校正觀察者間的隨機一致性，因此被認為是比簡單的百分比一致性更為可靠的度量方式。

![image](https://github.com/user-attachments/assets/3ed694e6-9406-4229-ab4e-b9f6007d1ea5)

![image](https://github.com/user-attachments/assets/a4801f5e-30c9-4184-927b-924d9389e887)
這個時候Kappa只剩下-0.00016787，非常的差。

## 回歸指標(Regression metrics)

回歸指標（Regression metrics）是用來評估回歸模型性能的度量標準。這些指標可以幫助我們理解模型的預測與真實值之間的差異。常用的回歸指標包括以下幾種：

1. 均方誤差 (Mean Squared Error, MSE)
MSE 是最常用的回歸評估指標之一，表示預測值與真實值之間的平均平方誤差。計算公式為：
![image](https://github.com/user-attachments/assets/3217a754-75b1-4483-9378-326407a0afa4)

2. 均方根誤差 (Root Mean Squared Error, RMSE)
RMSE 是 MSE 的平方根，保留了 MSE 的量綱，因此更容易與真實數據進行比較。計算公式為：
![image](https://github.com/user-attachments/assets/f6121cd0-e8d6-4165-a2f2-d08ff834f5f2)
RMSE 與 MSE 類似，值越小表示模型的預測越準確。

3. 平均絕對誤差 (Mean Absolute Error, MAE)
MAE 是預測值與真實值之間的平均絕對差異，計算公式為：
![image](https://github.com/user-attachments/assets/2bebf50f-e484-4ba8-bdc4-55b875a74086)
MAE 比 MSE 更容易解釋，因為它表示每次預測的平均誤差。


所以在回歸基本上只要評估時，評估指標只要用一樣的，哪個模型的評估指標越小的就代表那個模型越好。
